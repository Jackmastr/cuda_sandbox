** Rough Draft of Median Filter Memo **

Benchmark Speed Tests:

** (17, 17) **
SCIPY MEDFILT w/ 10 IMAGES:  23502.5917969 ms
SCIPY MEDFILT w/ 10 IMAGES:  23576.3867188 ms
SCIPY MEDFILT w/ 10 IMAGES:  24172.9804688 ms
SCIPY MEDFILT w/ 10 IMAGES:  23442.9550781 ms

FLOYD-WIRTH MEDFILT w/ 100 IMAGES:  19710.8925781 ms
FLOYD-WIRTH MEDFILT w/ 100 IMAGES:  19750.859375 ms
FLOYD-WIRTH MEDFILT w/ 100 IMAGES:  19999.5957031 ms
FLOYD-WIRTH MEDFILT w/ 100 IMAGES:  19697.3339844 ms

QUICKSELECT MEDFILT w/ 100 IMAGES:  24498.3847656 ms
QUICKSELECT MEDFILT w/ 100 IMAGES:  24723.3125 ms
QUICKSELECT MEDFILT w/ 100 IMAGES:  23643.8359375 ms
QUICKSELECT MEDFILT w/ 100 IMAGES:  23614.8046875 ms

PARTIAL SELECTION SORT MEDFILT w/ 100 IMAGES:  51824.328125 ms
PARTIAL SELECTION SORT MEDFILT w/ 100 IMAGES:  50571.7578125 ms
PARTIAL SELECTION SORT MEDFILT w/ 100 IMAGES:  50722.53125 ms
PARTIAL SELECTION SORT MEDFILT w/ 100 IMAGES:  50566.75 ms

TEXTURE MEDFILT w/ 100 IMAGES:  20866.4941406 ms
TEXTURE MEDFILT w/ 100 IMAGES:  20799.3105469 ms
TEXTURE MEDFILT w/ 100 IMAGES:  20840.0332031 ms
TEXTURE MEDFILT w/ 100 IMAGES:  20931.8085938 ms





// Maybe use this, maybe ignore it and redo it?
40x24 MEDFILT w/ 100 IMAGES:  19880.734375 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  19922.5429688 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  20084.6308594 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  19995.5566406 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ 






** (11, 11) **
SCIPY MEDFILT w/ 10 IMAGES:  10471.53125 ms
SCIPY MEDFILT w/ 10 IMAGES:  10488.9589844 ms
SCIPY MEDFILT w/ 10 IMAGES:  10331.2705078 ms
SCIPY MEDFILT w/ 10 IMAGES:  10337.0429688 ms

FLOYD-WIRTH MEDFILT w/ 100 IMAGES:  8797.54980469 ms
FLOYD-WIRTH MEDFILT w/ 100 IMAGES:  7632.80224609 ms
FLOYD-WIRTH MEDFILT w/ 100 IMAGES:  7565.90771484 ms
FLOYD-WIRTH MEDFILT w/ 100 IMAGES:  7671.72314453 ms

QUICKSELECT MEDFILT w/ 100 IMAGES:  10302.5517578 ms
QUICKSELECT MEDFILT w/ 100 IMAGES:  9160.59277344 ms
QUICKSELECT MEDFILT w/ 100 IMAGES:  9041.99121094 ms
QUICKSELECT MEDFILT w/ 100 IMAGES:  9072.41308594 ms

TEXTURE MEDFILT w/ 100 IMAGES:  9284.3828125 ms
TEXTURE MEDFILT w/ 100 IMAGES:  8169.09912109 ms
TEXTURE MEDFILT w/ 100 IMAGES:  8155.48291016 ms
TEXTURE MEDFILT w/ 100 IMAGES:  8134.83496094 ms


Pitfalls & Things I Learned:

- Very large input sizes use: #pragma comment(linker, "/HEAP:2000000")

- texture memory (doesn't really speed us up in this case)

- shared memory (not really good in this case, talk about overlap, yada yada)

- pad with zeros VS doing bounds checking with if()

- SELECTION Sort, Partial SELECTION Sort, QuickSelect, Floyd-Writh Select (with citation)

- Maybe I should just use an Jupyter Notebook (if only for the writeup so I can reference sections of the code)

- Be VERY(!) careful in keeping dimensions consistent (x, y, height, width, etc.) It is a terrible pain to go back after the fact and fix/debug

- Talk about my experience using CUDA-GDB --> b <func name>, cuda thread <thread index>, p to print, disp to display throughout, Need to comment out print statements to run it

- Block size of 32x32 has spontaneous problems sometimes (with the 9x9 kernel for whatever reason)

- Using format strings (escaping with another % or /)

- Talk about testing (problems)

- Talk about timing (problems) - Caching for the compilations





40x24 MEDFILT w/ 100 IMAGES:  59978.25 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  53365.6640625 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  47305.984375 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  21245.7675781 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  22022.7578125 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  21471.7519531 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  21070.3828125 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  20891.6542969 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  21063.0039062 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  21000.3984375 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  21046.6972656 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  20964.2207031 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  22438.7539062 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  21115.2773438 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  22663.0605469 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  19747.5019531 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  20027.2753906 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ CUDA_VISIBLE_DEVICES=0 python timing.py
done making it
40x24 MEDFILT w/ 100 IMAGES:  19890.9472656 ms
(env0) jacksons@snb1:~/cuda_projs/mf$ 

